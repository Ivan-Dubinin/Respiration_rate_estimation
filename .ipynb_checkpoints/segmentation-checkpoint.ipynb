{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea38e43e-712d-48bc-8f43-bef7100e01c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/gennadyshutkov/segmentation?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 192M/192M [00:07<00:00, 28.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/gennady/.cache/kagglehub/datasets/gennadyshutkov/segmentation/versions/1\n"
     ]
    }
   ],
   "source": [
    "# We are going to use dataset of segmented animals\n",
    "import kagglehub\n",
    "\n",
    "# The following code will only execute\n",
    "# successfully when compression is complete\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "PATH = \"gennadyshutkov/segmentation\" # YOUR PATH TO KAGGLE DATASET HERE\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"gennadyshutkov/segmentation\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20155e2e-7712-48df-a039-122d1def6829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files and Folders in Dataset Directory: ['train', 'val']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check directories in the dataset \n",
    "print(\"Files and Folders in Dataset Directory:\", os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00641079-e00a-43a9-94bf-f56adebda228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe layter we will use single dirrectory and split on train and val in the runtime\n",
    "\n",
    "if set(os.listdir(path)) == set(['train', 'val']):\n",
    "    tr_img_dir, tr_mask_dir = f\"{path}/train/images\", f\"{path}/train/masks\"\n",
    "    val_img_dir, val_mask_dir = f\"{path}/val/images\", f\"{path}/val/masks\"\n",
    "else:\n",
    "    raise FileNotFoundError(\"Dataset is incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce24d96-0018-4c05-8c39-6745f5f4044b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gennady/.cache/kagglehub/datasets/gennadyshutkov/segmentation/versions/1/train/images'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0f4f18-d26d-4cf5-a553-91a97ff8854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "class Segmentation(Dataset):\n",
    "    '''\n",
    "    This Class defines our own dataloader of the kaggle dataset.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        '''\n",
    "        image_dir - dirrectory with images\n",
    "        mask_dir - dirrectory with masks\n",
    "        transform - any image transformation for data augmentation (cropp, flip, resize, filter)\n",
    "        '''\n",
    "\n",
    "        # according to dataset, images are all jpg files and masks are all png files\n",
    "        self.image_paths = sorted(Path(image_dir).glob(\"*.jpg\"))\n",
    "        self.mask_paths = sorted(Path(mask_dir).glob(\"*.png\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Get single image from the loaded dataset\n",
    "        idx - number of image\n",
    "        '''\n",
    "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(self.mask_paths[idx]))\n",
    "        # the mask only has 4 different parts - body, legs, head, tail\n",
    "        # we want to remove any misleading values\n",
    "        mask = np.clip(mask, 0, 4)\n",
    "\n",
    "        if self.transform:\n",
    "            tmp = self.transform(image=image, mask=mask)\n",
    "            image, mask = tmp['image'], tmp['mask']\n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        # number of images in dataset\n",
    "        return len(self.image_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
