{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f25ea94-8bbf-42ec-8c76-8ffd22b3bbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use dataset of segmented animals\n",
    "import kagglehub\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea38e43e-712d-48bc-8f43-bef7100e01c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/gennadyshutkov/segmentation?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 192M/192M [00:07<00:00, 28.2MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/gennady/.cache/kagglehub/datasets/gennadyshutkov/segmentation/versions/1\n"
     ]
    }
   ],
   "source": [
    "PATH = \"gennadyshutkov/segmentation\" # YOUR PATH TO KAGGLE DATASET HERE\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"gennadyshutkov/segmentation\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20155e2e-7712-48df-a039-122d1def6829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files and Folders in Dataset Directory: ['train', 'val']\n"
     ]
    }
   ],
   "source": [
    "# Check directories in the dataset  \n",
    "print(\"Files and Folders in Dataset Directory:\", os.listdir(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00641079-e00a-43a9-94bf-f56adebda228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe layter we will use single dirrectory and split on train and val in the runtime\n",
    "if set(os.listdir(path)) == set(['train', 'val']):\n",
    "    tr_img_dir, tr_mask_dir = f\"{path}/train/images\", f\"{path}/train/masks\"\n",
    "    val_img_dir, val_mask_dir = f\"{path}/val/images\", f\"{path}/val/masks\"\n",
    "else:\n",
    "    raise FileNotFoundError(\"Dataset is incorrect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce24d96-0018-4c05-8c39-6745f5f4044b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/gennady/.cache/kagglehub/datasets/gennadyshutkov/segmentation/versions/1/train/images'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce0f4f18-d26d-4cf5-a553-91a97ff8854b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segmentation(Dataset):\n",
    "    '''\n",
    "    This Class defines our own dataloader of the kaggle dataset.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        '''\n",
    "        image_dir - dirrectory with images\n",
    "        mask_dir - dirrectory with masks\n",
    "        transform - any image transformation for data augmentation (cropp, flip, resize, filter)\n",
    "        '''\n",
    "\n",
    "        # according to dataset, images are all jpg files and masks are all png files\n",
    "        self.image_paths = sorted(Path(image_dir).glob(\"*.jpg\"))\n",
    "        self.mask_paths = sorted(Path(mask_dir).glob(\"*.png\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''\n",
    "        Get single image from the loaded dataset\n",
    "        idx - number of image\n",
    "        '''\n",
    "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
    "        mask = np.array(Image.open(self.mask_paths[idx]))\n",
    "        # the mask only has 4 different parts - body, legs, head, tail\n",
    "        # we want to remove any misleading values\n",
    "        mask = np.clip(mask, 0, 4)\n",
    "\n",
    "        if self.transform:\n",
    "            tmp = self.transform(image=image, mask=mask)\n",
    "            image, mask = tmp['image'],tmp['mask']\n",
    "            \n",
    "        return image, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        # number of images in dataset\n",
    "        return len(self.image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fea36919-2176-4c0d-a787-4bf22d480df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we are using albumentations library to get image augmentation and reduce model overfitting on our small dataset\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)), # number were taken from the internet thread\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# for the validation dataset, we do not apply augmentation to work with 'pure' image\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7fac3e78-40b6-4c4c-9ae0-0fb50eeaf74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "train_dataset = Segmentation(tr_img_dir, tr_mask_dir, transform=train_transform)\n",
    "val_dataset = Segmentation(val_img_dir, val_mask_dir, transform=val_transform)\n",
    "\n",
    "# shuffle dataset\n",
    "# in future we are going to shuffle first and then split into train and validation\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9a3f5fe-e31a-4176-8236-db4bedde3c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Samples: 1737\n",
      "Validation Samples: 435\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Samples: {len(train_dataset)}\")\n",
    "print(f\"Validation Samples: {len(val_dataset)}\")\n",
    "# Here training dataset is pretty small, however hopefully we can achieve sufficient accuracy \n",
    "# We are going to use pretrained U-net model for the segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1062b5ab-c916-4f89-b7af-8b4e1464a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_img(dataset, num_samples=3):\n",
    "    fig, axes = plt.subplots(num_samples, 2, figsize=(10, num_samples * 4))\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        # Pick a random image from the dataset\n",
    "        img, mask = dataset[random.randint(0, len(dataset) - 1)]\n",
    "\n",
    "        # Convert tensor to a NumPy image\n",
    "        img_np = img.permute(1, 2, 0).numpy()\n",
    "        mask_np = mask.numpy()\n",
    "\n",
    "        # Show the image\n",
    "        axes[i, 0].imshow(img_np)\n",
    "        axes[i, 0].set_title(\"Image\")\n",
    "\n",
    "        # Show the corresponding mask\n",
    "        axes[i, 1].imshow(mask_np, cmap=\"jet\", alpha=0.6)\n",
    "        axes[i, 1].set_title(\"Mask\")\n",
    "\n",
    "        # Remove axis labels for a cleaner look\n",
    "        for ax in axes[i]:\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run the function to check if everything is correct\n",
    "draw_img(train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
